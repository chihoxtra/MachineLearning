{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis little program is a crawler which crawls the data from etw.nextdigital.com.hk and extract all the \\nrestaurants information\\n- beautiful soup was used to crawl infinite scrolling page\\n- regex is used to extract values\\n- data are stored in both local JSON fire and in SQLite DB\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This little program is a crawler which crawls the data from etw.nextdigital.com.hk and extract all the \n",
    "restaurants information\n",
    "- beautiful soup was used to crawl infinite scrolling page\n",
    "- regex is used to extract values\n",
    "- data are stored in both local JSON fire and in SQLite DB\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import json\n",
    "import ssl\n",
    "import re\n",
    "import time\n",
    "import sqlite3\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadMasterJSON(filePath, jsonFileName):\n",
    "    with open(filePath + jsonFileName) as fp:\n",
    "        f = json.load(fp)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTableAndWriteData(db, data_elements, data_cat):\n",
    "    # define DB path and name\n",
    "    c = db.cursor()\n",
    "    \n",
    "    table_name = data_cat.upper()\n",
    "    key_field = data_cat.lower() + '_id'\n",
    "    value = data_cat.lower()\n",
    "    \n",
    "    tableSQL = (\"CREATE TABLE IF NOT EXISTS \" + table_name \n",
    "                + \" (\" + key_field + \" INTEGER NOT NULL UNIQUE PRIMARY KEY AUTOINCREMENT,\" \n",
    "                + value + \" varchar(128) NOT NULL UNIQUE);\")\n",
    "    \n",
    "    # try to create \n",
    "    try:\n",
    "        c.execute(tableSQL)\n",
    "    except ValueError:\n",
    "        print(ValueError)\n",
    "    \n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    for data in data_elements:\n",
    "        query = \"INSERT OR REPLACE into \" + table_name + \" values (null,'\" + data + \"')\"\n",
    "        try:\n",
    "            c.execute(query)\n",
    "        except ValueError:\n",
    "            print(ValueError)\n",
    "            continue\n",
    "        count += 1\n",
    "    \n",
    "    print(str(count) + \" records added to table \" + table_name)\n",
    "    \n",
    "    db.commit()\n",
    "    c.close()\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieveDB(db, data_cat):\n",
    "    c = db.cursor()\n",
    "    elements = []\n",
    "    query = \"SELECT \" + data_cat + \" from \" + data_cat.upper() \n",
    "    \n",
    "    try:\n",
    "        elements = c.execute(query).fetchall()\n",
    "        \n",
    "        #db.row_factory = lambda cursor, row: row[0]\n",
    "        elements = c.execute(query).fetchall()\n",
    "        elementList = [ls[0] for ls in elements]\n",
    "        \n",
    "    except ValueError:\n",
    "        print(ValueError)\n",
    "    \n",
    "    return elementList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepareMasterSeedList(district_elements, cuisine_elements, foodtype_elements, updateDB = True):\n",
    "    MasterSeedURL = []\n",
    "    baseURL = \"http://etw.nextdigital.com.hk/search/restaurant/?\"\n",
    "    \n",
    "        \n",
    "    \n",
    "    for i in range(len(district_elements)):\n",
    "        d = baseURL + \"district=\" + district_elements[i]\n",
    "        MasterSeedURL.append(d)\n",
    "\n",
    "    for i in range(len(cuisine_elements)):\n",
    "        d = baseURL + \"cuisine=\" + cuisine_elements[i]\n",
    "        MasterSeedURL.append(d)\n",
    "\n",
    "    for i in range(len(foodtype_elements)):\n",
    "        d = baseURL + \"foodtype=\" + foodtype_elements[i]\n",
    "        MasterSeedURL.append(d)   \n",
    "\n",
    "    print(\"Masterlist length: \" +  str(len(MasterSeedURL)))\n",
    "        \n",
    "        \n",
    "    return MasterSeedURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crawlMetaInfo(url):\n",
    "    \n",
    "    browser = webdriver.Chrome('/Users/samuelpun_old/Desktop/MLfolders/chromedriver')\n",
    "\n",
    "    browser.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    elem = browser.find_element_by_tag_name(\"body\")\n",
    "\n",
    "        \n",
    "    # extract Search Options seeds\n",
    "    district_elements = extractElements(browser, \"selected_district\", \"value\", \"find_elements_by_name\")\n",
    "    cuisine_elements = extractElements(browser, \"selected_cuisine\", \"value\", \"find_elements_by_name\")\n",
    "    foodtype_elements = extractElements(browser, \"selected_foodtype\", \"value\", \"find_elements_by_name\")\n",
    "    \n",
    "    browser.close()\n",
    "                                             \n",
    "    return district_elements, cuisine_elements, foodtype_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractElements(browserObj, tagName, attr, method):\n",
    "    \n",
    "    if method == \"find_elements_by_name\":\n",
    "        elements = browserObj.find_elements_by_name(tagName)\n",
    "    elif method  == \"find_elements_by_class_name\":\n",
    "        elements = browserObj.find_elements_by_class_name(tagName)\n",
    "        \n",
    "    snippets = []\n",
    "    \n",
    "    for item in elements:\n",
    "        snippets.append(item.get_attribute(attr))\n",
    "    \n",
    "    return snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crawlRestInfo(url, tag, pageDownNumber = 100, pageDownSleepTime = 5.0, infScroll = False):\n",
    "    \n",
    "    if infScroll == False:\n",
    "        ctx = ssl.create_default_context()\n",
    "        ctx.check_hostname = False\n",
    "        ctx.verify_mode = ssl.CERT_NONE\n",
    "    \n",
    "        html = urllib.request.urlopen(url, context=ctx).read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "        # Retrieve all of the anchor tags\n",
    "        snippets = soup(tag)\n",
    "    \n",
    "    else:\n",
    "        browser = webdriver.Chrome('/Users/samuelpun_old/Desktop/MLfolders/chromedriver')\n",
    "\n",
    "        browser.get(url)\n",
    "        time.sleep(pageDownSleepTime)\n",
    "\n",
    "        elem = browser.find_element_by_tag_name(\"body\")\n",
    "\n",
    "        # Generate auto pagedown\n",
    "        lastHeight = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        while pageDownNumber:\n",
    "            \n",
    "            elem.send_keys(Keys.PAGE_DOWN)\n",
    "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5.0)\n",
    "            newHeight = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "            if newHeight == lastHeight:\n",
    "                break\n",
    "            else:\n",
    "                lastHeight = newHeight\n",
    "            pageDownNumber-=1\n",
    "\n",
    "        # extract restaurants class\n",
    "        restHTML_elementsList = extractElements(browser, \"result-restaurant-list\", \n",
    "                                             \"innerHTML\", \"find_elements_by_class_name\")\n",
    "        browser.close()\n",
    "        \n",
    "                                             \n",
    "    return restHTML_elementsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addrToDistrictID(addr, district_elements):\n",
    "    \n",
    "    db = sqlite3.connect(filePath + dbName)\n",
    "    c = db.cursor()\n",
    "    district_id = \"\"\n",
    "    \n",
    "    l = len(addr)\n",
    "    for i in range(l):\n",
    "        substr = addr[0:1-i]\n",
    "        if substr in district_elements:\n",
    "            query = \"SELECT DISTRICT.district_id from DISTRICT where DISTRICT.district = '\" + substr + \"'\"\n",
    "            district_id = c.execute(query).fetchall()\n",
    "            district_id = [ls[0] for ls in district_id]\n",
    "            #print(district_id)\n",
    "    \n",
    "    if len(district_id) > 0:\n",
    "        db.close()\n",
    "        district_id = district_id[0]\n",
    "    else:\n",
    "        print(addr)\n",
    "        district_id = 1\n",
    "    \n",
    "    return district_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def districtToDistrict_ID(district, district_elements):\n",
    "    \n",
    "    db = sqlite3.connect(filePath + dbName)\n",
    "    c = db.cursor()\n",
    "    district_id = \"\"\n",
    "    \n",
    "    if district in district_elements:\n",
    "        query = \"SELECT DISTRICT.district_id from DISTRICT where DISTRICT.district = '\" + district + \"'\"\n",
    "        district_id = c.execute(query).fetchall()\n",
    "        district_id = [ls[0] for ls in district_id]\n",
    "            #print(district_id)\n",
    "    \n",
    "    if len(district_id) > 0:\n",
    "        db.close()\n",
    "        district_id = district_id[0]\n",
    "    else:\n",
    "        print(addr)\n",
    "        district_id = 1\n",
    "    \n",
    "    return district_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RestHTMLtoList(restHTML_elementsList, restMasterList, district_elements):\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    # from a list of href exact restaurant and new masterList info\n",
    "    for i in range(len(restHTML_elementsList)):\n",
    "        #print(restHTML_elementsList[0])\n",
    "        restID = re.findall('\\\\/restaurant\\\\/([0-9]+)\\\\/.*\\\\\"',str(restHTML_elementsList[i]))\n",
    "        url_tags = re.findall('\\\\/restaurant\\\\/[0-9]+\\\\/(.*)\\\\\"',str(restHTML_elementsList[i]))\n",
    "\n",
    "        for u in url_tags[0].split('-'):\n",
    "            if u in district_elements:\n",
    "                district_id = districtToDistrict_ID(u, district_elements)\n",
    "        \n",
    "        name = re.findall('ar-name\\\\\"\\\\>(.+)\\\\<\\\\/div\\\\>',str(restHTML_elementsList[i]))\n",
    "        tel = re.findall('ar-tel\\\\\"\\\\>([0-9]+\\s[0-9]+)\\\\<\\\\/div\\\\>',str(restHTML_elementsList[i]))\n",
    "        addr = re.findall('ar-address\\\\\"\\\\>(.+)\\\\<\\\\/div\\\\>',str(restHTML_elementsList[i]))\n",
    "        tags = re.findall('ar-cuisine\\\\\"\\\\>\\\\\\n\\s+(.+)\\\\<\\\\/div\\\\>',str(restHTML_elementsList[i]))\n",
    "        rating = re.findall('editorialrating\\\\\"\\\\>(\\S+)\\\\<\\\\/span\\\\>',str(restHTML_elementsList[i]))\n",
    "\n",
    "\n",
    "        rest = {}\n",
    "        \n",
    "        if len(restID) > 0:\n",
    "            #print(rest)\n",
    "            rest['ID'] = restID[0]\n",
    "            \n",
    "        if len(tags) > 0:\n",
    "            tagsList = tags[0].split('|')\n",
    "            for i in range(len(tagsList)):\n",
    "                tagsList[i] = tagsList[i].strip()\n",
    "            rest['tags'] = tagsList\n",
    "            #print(rest['tags'])\n",
    "            \n",
    "        if len(name) > 0: \n",
    "            rest['name'] = name[0]\n",
    "            \n",
    "        \n",
    "        if len(rating) > 0:     \n",
    "            rest['rating'] = rating[0]\n",
    "        else:\n",
    "            rest['rating'] = ''\n",
    "        \n",
    "        \n",
    "        if len(tel) > 0:     \n",
    "            rest['tel'] = tel[0]\n",
    "        else:\n",
    "            rest['tel'] = ''\n",
    "        \n",
    "        if len(addr) > 0: \n",
    "            rest['addr'] = addr[0]\n",
    "            \n",
    "            \"\"\"\n",
    "            #remove '香港' if it is in the address\n",
    "            if '香港' in addr[0] and not ('香港仔' in addr[0]):\n",
    "                start = addr[0].index('香港') + len('香港')\n",
    "                newadd = addr[0][start: -1]\n",
    "            else:\n",
    "                newadd = addr[0]\n",
    "\n",
    "            district_id = addrToDistrictID(newadd, district_elements)\n",
    "            \"\"\"\n",
    "        else:\n",
    "            rest['addr'] = ''\n",
    "        \n",
    "        if len(str(district_id)) > 0: \n",
    "            rest['district_id'] = district_id\n",
    "        else:\n",
    "            rest['district_id'] = ''\n",
    "            print(\"no district_id found\")\n",
    "            \n",
    "        if restID[0] in restMasterList:\n",
    "            continue\n",
    "        else:\n",
    "            #print(restID[0])\n",
    "            #print(rest)\n",
    "            restMasterList[restID[0]] = rest\n",
    "            count = count + 1\n",
    "    \n",
    "    print(str(len(restHTML_elementsList)) + \" records found. \" + str(count) + \n",
    "          \" records updated. Total record: \" + str(len(restMasterList)))\n",
    "\n",
    "         \n",
    "    return restMasterList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processCrawlList(filePath, seedMasterList, crawlAndSaveOnly, district_elements, restMasterList = {}):\n",
    "    \n",
    "    pageDownNumber = 2000\n",
    "    pageDownSleepTime = 5.0\n",
    "    saveLocalFile = True\n",
    "    \n",
    "    # scan thru the seedMasterList go get a list of href\n",
    "    url_count = 0\n",
    "    \n",
    "    for i in range(len(seedMasterList)):\n",
    "        print(\"fetching \" + str(i) + \"th URL out of \" + str(len(seedMasterList)))\n",
    "        this_url = seedMasterList[i]\n",
    "        restHTML_elementsList = crawlRestInfo(this_url, 'a', pageDownNumber, pageDownSleepTime, True) \n",
    "        \n",
    "        if saveLocalFile == True:\n",
    "            fileCount = 0\n",
    "            for rest_snippet in range(len(restHTML_elementsList)):\n",
    "                with open(filePath + str(i) + \"-\" + str(rest_snippet) + \".txt\", \"w\") as file:\n",
    "                    file.write(restHTML_elementsList[rest_snippet])\n",
    "                    fileCount += 1\n",
    "            print(str(fileCount) + \" files saved to: \" + str(filePath))\n",
    "        \n",
    "        if crawlAndSaveOnly == False:\n",
    "            restMasterList = RestHTMLtoList(restHTML_elementsList, restMasterList, district_elements)\n",
    "        \n",
    "        url_count += 1\n",
    "    \n",
    "    print(str(url_count) + \" url fetched\")\n",
    "\n",
    "    return restMasterList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadTxtFiletoElementsList(filePath):\n",
    "    \n",
    "    restHTML_elementsList = []\n",
    "    \n",
    "    for file in os.listdir(filePath):\n",
    "        if file.endswith(\".txt\"):\n",
    "            #print(os.path.join(filePath, file))\n",
    "            with open(filePath + file, \"r\") as file:\n",
    "                rest_snippet = file.read()\n",
    "                restHTML_elementsList.append(rest_snippet)\n",
    "    \n",
    "    print(str(len(restHTML_elementsList)) + \" files appended.\")\n",
    "    \n",
    "    return restHTML_elementsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveData(filePath, dbName, jsonFileName, restMasterList, JSON = True, DB = True):\n",
    "    \n",
    "    if JSON == True:\n",
    "        # save file as JSON format\n",
    "        with open((filePath + jsonFileName), 'w+') as fp:\n",
    "            json.dump(restMasterList, fp)\n",
    "            print( str(len(restMasterList)) + \" records saved to local JSON file: \" + jsonFileName)\n",
    "            #existingRecord = dict(json.load(fp))\n",
    "    \n",
    "    if DB == True:\n",
    "        db = sqlite3.connect(filePath + dbName)\n",
    "        c = db.cursor()\n",
    "        \n",
    "        create_table_sql = \"\"\"CREATE TABLE IF NOT EXISTS ETWRestsDB (\n",
    "                                        rest_id text PRIMARY KEY NOT NULL,\n",
    "                                        addr text,\n",
    "                                        name text NOT NULL,\n",
    "                                        rating text,\n",
    "                                        tags text,\n",
    "                                        tel text,\n",
    "                                        district_id INTEGER,\n",
    "                                        foreign key(district_id) REFERENCES DISTRICT(district_id)\n",
    "                                    );\"\"\"\n",
    "        try:\n",
    "            c.execute('DROP TABLE IF EXISTS ETWRestsDB;')\n",
    "            c.execute(create_table_sql)\n",
    "        except ValueError:\n",
    "            print(ValueError)\n",
    "        \n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        query = \"INSERT or REPLACE into ETWRestsDB values (?,?,?,?,?,?,?)\"\n",
    "        columns = ['addr', 'name', 'rating', 'tags', 'tel', 'district_id']\n",
    "        for restid, data in restMasterList.items():\n",
    "            keys = (restid,) + tuple(str(data[c]) for c in columns)\n",
    "            #print(str(keys))\n",
    "            c.execute(query, keys)\n",
    "            count = count + 1\n",
    "        \n",
    "        db.commit()\n",
    "        c.close()\n",
    "        print(str(count) + \" number of records inserted in DB\")\n",
    "    \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateRelTable(filePath, dbName, restMasterList):\n",
    "    \n",
    "    db = sqlite3.connect(filePath + dbName)    \n",
    "    c = db.cursor()\n",
    "    \n",
    "    tableSQL_rest_cuisine = \"\"\"CREATE TABLE IF NOT EXISTS REST_CUISINE ( \n",
    "                                    rest_id TEXT NOT NULL ,\n",
    "                                    cuisine_id INTEGER NOT NULL,\n",
    "                                    PRIMARY KEY(rest_id, cuisine_id),\n",
    "                                    foreign key(rest_id) REFERENCES ETWRestsDB(rest_id),\n",
    "                                    foreign key(cuisine_id) REFERENCES CUISINE(cuisine_id)\n",
    "                                    );\"\"\"\n",
    "\n",
    "    tableSQL_rest_foodtype = \"\"\"CREATE TABLE IF NOT EXISTS REST_FOODTYPE ( \n",
    "                                    rest_id TEXT NOT NULL ,\n",
    "                                    foodtype_id INTEGER NOT NULL,\n",
    "                                    PRIMARY KEY(rest_id, foodtype_id),\n",
    "                                    foreign key(rest_id) REFERENCES ETWRestsDB(rest_id),\n",
    "                                    foreign key(foodtype_id) REFERENCES FOODTYPE(foodtype_id)\n",
    "                                    );\"\"\"    \n",
    "       \n",
    "    c.execute(tableSQL_rest_cuisine)\n",
    "    c.execute(tableSQL_rest_foodtype)\n",
    "    \n",
    "\n",
    "    for restid, data in restMasterList.items():\n",
    "        #print(str(restid) + \": \")\n",
    "        for t in data['tags']:\n",
    "            f_query = \"select foodtype_id from FOODTYPE where foodtype = '\" + t + \"'\"\n",
    "            f_id = c.execute(f_query).fetchall()\n",
    "            foodtype_id = [ls[0] for ls in f_id]\n",
    "            if len(foodtype_id) > 0:\n",
    "                query = (\"INSERT OR REPLACE into REST_FOODTYPE values (\" + str(restid) \n",
    "                         + \",\" + str(foodtype_id[0]) + \");\")\n",
    "                try:\n",
    "                    c.execute(query)\n",
    "                except ValueError:\n",
    "                    print(ValueError)\n",
    "            \n",
    "            c_query = \"select cuisine_id from CUISINE where cuisine = '\" + t + \"'\"\n",
    "            c_id = c.execute(c_query).fetchall()\n",
    "            cuisine_id = [ls[0] for ls in c_id]\n",
    "            if len(cuisine_id) > 0:\n",
    "                query = (\"INSERT OR REPLACE into REST_CUISINE values (\" \n",
    "                         + str(restid) + \",\" + str(cuisine_id[0]) + \");\")    \n",
    "                try:\n",
    "                    c.execute(query)\n",
    "                except ValueError:\n",
    "                    print(ValueError)\n",
    "    db.commit()\n",
    "    c.close()               \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 records added to table DISTRICT\n",
      "68 records added to table CUISINE\n",
      "94 records added to table FOODTYPE\n",
      "Masterlist length: 253\n",
      "fetching 0th URL out of 253\n",
      "0 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "0 records found. 0 records updated. Total record: 0\n",
      "fetching 1th URL out of 253\n",
      "515 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "515 records found. 515 records updated. Total record: 515\n",
      "fetching 2th URL out of 253\n",
      "862 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "862 records found. 862 records updated. Total record: 1377\n",
      "fetching 3th URL out of 253\n",
      "401 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "401 records found. 401 records updated. Total record: 1778\n",
      "fetching 4th URL out of 253\n",
      "164 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "164 records found. 164 records updated. Total record: 1942\n",
      "fetching 5th URL out of 253\n",
      "72 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "72 records found. 72 records updated. Total record: 2014\n",
      "fetching 6th URL out of 253\n",
      "57 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "57 records found. 57 records updated. Total record: 2071\n",
      "fetching 7th URL out of 253\n",
      "32 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "32 records found. 32 records updated. Total record: 2103\n",
      "fetching 8th URL out of 253\n",
      "42 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "42 records found. 42 records updated. Total record: 2145\n",
      "fetching 9th URL out of 253\n",
      "97 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "97 records found. 97 records updated. Total record: 2242\n",
      "fetching 10th URL out of 253\n",
      "15 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "15 records found. 15 records updated. Total record: 2257\n",
      "fetching 11th URL out of 253\n",
      "57 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "57 records found. 57 records updated. Total record: 2314\n",
      "fetching 12th URL out of 253\n",
      "55 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "55 records found. 55 records updated. Total record: 2369\n",
      "fetching 13th URL out of 253\n",
      "7 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "7 records found. 7 records updated. Total record: 2376\n",
      "fetching 14th URL out of 253\n",
      "15 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "15 records found. 15 records updated. Total record: 2391\n",
      "fetching 15th URL out of 253\n",
      "4 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "4 records found. 4 records updated. Total record: 2395\n",
      "fetching 16th URL out of 253\n",
      "2 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "2 records found. 2 records updated. Total record: 2397\n",
      "fetching 17th URL out of 253\n",
      "4 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "4 records found. 4 records updated. Total record: 2401\n",
      "fetching 18th URL out of 253\n",
      "20 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "20 records found. 20 records updated. Total record: 2421\n",
      "fetching 19th URL out of 253\n",
      "122 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "122 records found. 122 records updated. Total record: 2543\n",
      "fetching 20th URL out of 253\n",
      "184 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "184 records found. 184 records updated. Total record: 2727\n",
      "fetching 21th URL out of 253\n",
      "46 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "46 records found. 46 records updated. Total record: 2773\n",
      "fetching 22th URL out of 253\n",
      "18 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "18 records found. 18 records updated. Total record: 2791\n",
      "fetching 23th URL out of 253\n",
      "30 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "30 records found. 30 records updated. Total record: 2821\n",
      "fetching 24th URL out of 253\n",
      "16 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "16 records found. 16 records updated. Total record: 2837\n",
      "fetching 25th URL out of 253\n",
      "88 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "88 records found. 88 records updated. Total record: 2925\n",
      "fetching 26th URL out of 253\n",
      "19 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "19 records found. 19 records updated. Total record: 2944\n",
      "fetching 27th URL out of 253\n",
      "82 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "82 records found. 82 records updated. Total record: 3026\n",
      "fetching 28th URL out of 253\n",
      "16 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "16 records found. 16 records updated. Total record: 3042\n",
      "fetching 29th URL out of 253\n",
      "7 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "7 records found. 7 records updated. Total record: 3049\n",
      "fetching 30th URL out of 253\n",
      "0 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "0 records found. 0 records updated. Total record: 3049\n",
      "fetching 31th URL out of 253\n",
      "118 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "118 records found. 118 records updated. Total record: 3167\n",
      "fetching 32th URL out of 253\n",
      "381 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "381 records found. 381 records updated. Total record: 3548\n",
      "fetching 33th URL out of 253\n",
      "1275 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "1275 records found. 1275 records updated. Total record: 4823\n",
      "fetching 34th URL out of 253\n",
      "158 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "158 records found. 158 records updated. Total record: 4981\n",
      "fetching 35th URL out of 253\n",
      "228 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "228 records found. 228 records updated. Total record: 5209\n",
      "fetching 36th URL out of 253\n",
      "142 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "142 records found. 142 records updated. Total record: 5351\n",
      "fetching 37th URL out of 253\n",
      "26 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "26 records found. 26 records updated. Total record: 5377\n",
      "fetching 38th URL out of 253\n",
      "13 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "13 records found. 13 records updated. Total record: 5390\n",
      "fetching 39th URL out of 253\n",
      "60 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "60 records found. 60 records updated. Total record: 5450\n",
      "fetching 40th URL out of 253\n",
      "25 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "25 records found. 25 records updated. Total record: 5475\n",
      "fetching 41th URL out of 253\n",
      "44 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "44 records found. 44 records updated. Total record: 5519\n",
      "fetching 42th URL out of 253\n",
      "23 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "23 records found. 23 records updated. Total record: 5542\n",
      "fetching 43th URL out of 253\n",
      "120 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "120 records found. 120 records updated. Total record: 5662\n",
      "fetching 44th URL out of 253\n",
      "26 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "26 records found. 26 records updated. Total record: 5688\n",
      "fetching 45th URL out of 253\n",
      "63 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "63 records found. 63 records updated. Total record: 5751\n",
      "fetching 46th URL out of 253\n",
      "24 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "24 records found. 24 records updated. Total record: 5775\n",
      "fetching 47th URL out of 253\n",
      "31 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "31 records found. 31 records updated. Total record: 5806\n",
      "fetching 48th URL out of 253\n",
      "98 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "98 records found. 98 records updated. Total record: 5904\n",
      "fetching 49th URL out of 253\n",
      "63 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "63 records found. 63 records updated. Total record: 5967\n",
      "fetching 50th URL out of 253\n",
      "72 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "72 records found. 72 records updated. Total record: 6039\n",
      "fetching 51th URL out of 253\n",
      "13 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "13 records found. 13 records updated. Total record: 6052\n",
      "fetching 52th URL out of 253\n",
      "46 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "46 records found. 46 records updated. Total record: 6098\n",
      "fetching 53th URL out of 253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "142 records found. 142 records updated. Total record: 6240\n",
      "fetching 54th URL out of 253\n",
      "12 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "12 records found. 12 records updated. Total record: 6252\n",
      "fetching 55th URL out of 253\n",
      "35 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "35 records found. 35 records updated. Total record: 6287\n",
      "fetching 56th URL out of 253\n",
      "22 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "22 records found. 22 records updated. Total record: 6309\n",
      "fetching 57th URL out of 253\n",
      "82 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "82 records found. 82 records updated. Total record: 6391\n",
      "fetching 58th URL out of 253\n",
      "0 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "0 records found. 0 records updated. Total record: 6391\n",
      "fetching 59th URL out of 253\n",
      "289 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "289 records found. 289 records updated. Total record: 6680\n",
      "fetching 60th URL out of 253\n",
      "844 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "844 records found. 844 records updated. Total record: 7524\n",
      "fetching 61th URL out of 253\n",
      "53 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "53 records found. 53 records updated. Total record: 7577\n",
      "fetching 62th URL out of 253\n",
      "12 files saved to: /Users/samuelpun_old/Desktop/MLfolders/ETWdata/\n",
      "12 records found. 12 records updated. Total record: 7589\n",
      "fetching 63th URL out of 253\n"
     ]
    }
   ],
   "source": [
    "#url = input('Enter - ')\n",
    "crawlAndUpdateMetaInfo = True\n",
    "crawlAndSaveOnly = False\n",
    "filePath = '/Users/samuelpun_old/Desktop/MLfolders/ETWdata/'\n",
    "dbName = \"ETW1.db\"\n",
    "jsonFileName = \"restMasterList.json\"\n",
    "\n",
    "seedMasterList = []\n",
    "\n",
    "# Extract Search Meta Data\n",
    "if crawlAndUpdateMetaInfo == True:\n",
    "    #crawl the data elements\n",
    "    district_elements, cuisine_elements, foodtype_elements = crawlMetaInfo(\"http://etw.nextdigital.com.hk\")\n",
    "    #write to DB\n",
    "    db = sqlite3.connect(filePath + dbName)\n",
    "    createTableAndWriteData(db, district_elements, 'district')\n",
    "    createTableAndWriteData(db, cuisine_elements, 'cuisine')\n",
    "    createTableAndWriteData(db, foodtype_elements, 'foodtype')\n",
    "    db.close()\n",
    "else:\n",
    "    # retrieve from db\n",
    "    db = sqlite3.connect(filePath + dbName)\n",
    "    district_elements = retrieveDB(db, 'district')\n",
    "    cuisine_elements = retrieveDB(db, 'cuisine')\n",
    "    foodtype_elements = retrieveDB(db, 'foodtype')\n",
    "    db.close()\n",
    "\n",
    "# Prepare Master Crawl List\n",
    "seedMasterList = prepareMasterSeedList(district_elements, cuisine_elements, foodtype_elements)\n",
    "\n",
    "# Crawl the MasterList  seedMasterList[10:12]\n",
    "restMasterList = processCrawlList(filePath, seedMasterList, crawlAndSaveOnly, district_elements)\n",
    "\n",
    "# Load from DB\n",
    "if crawlAndSaveOnly == True:\n",
    "    # dont expect to get direct list from the previous process\n",
    "    restHTML_elementsList = loadTxtFiletoElementsList(filePath)\n",
    "    restMasterList = RestHTMLtoList(restHTML_elementsList, restMasterList, district_elements)\n",
    "\n",
    "saveData(filePath, dbName, jsonFileName, restMasterList)\n",
    "updateRelTable(filePath, dbName, restMasterList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saveData(filePath, dbName, jsonFileName, restMasterList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = loadMasterJSON(filePath, jsonFileName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
